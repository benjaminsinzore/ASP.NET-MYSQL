{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUJeNll6eZ9J/ukcezkjNa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminsinzore/ASP.NET-MYSQL/blob/main/Fine_Tuning_Moshi_7B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Started with Fine-Tuning Moshi 7B\n",
        "\n",
        "This notebook shows you a simple example of how to LoRA finetune Moshi 7B. You can run this notebook in Google Colab using a A100 GPU.\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github//kyutai-labs/moshi-finetune/blob/main/tutorials/moshi_finetune.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "Check out `moshi-finetune` Github repo to learn more: https://github.com/kyutai-labs/moshi-finetune/\n"
      ],
      "metadata": {
        "id": "lwQlKXhq7iPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "Clone the `moshi-finetune` repo:\n"
      ],
      "metadata": {
        "id": "K5I4CAfE7sB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cmek_Wr66zE"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/kyutai-labs/moshi-finetune.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install all required dependencies:\n"
      ],
      "metadata": {
        "id": "vCEMRY8_7XMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -e /content/moshi-finetune"
      ],
      "metadata": {
        "id": "aBfeJT0A9Lvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset\n"
      ],
      "metadata": {
        "id": "hbpYKcOU9RUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from huggingface_hub import snapshot_download\n",
        "import time\n",
        "\n",
        "Path(\"/content/data/daily-talk-contiguous\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the dataset with retries and delay\n",
        "local_dir = None\n",
        "retries = 3  # Number of retries\n",
        "delay = 5    # Delay in seconds between retries\n",
        "\n",
        "for i in range(retries):\n",
        "    try:\n",
        "        local_dir = snapshot_download(\n",
        "            \"kyutai/DailyTalkContiguous\",\n",
        "            repo_type=\"dataset\",\n",
        "            local_dir=\"/content/data/daily-talk-contiguous\",\n",
        "        )\n",
        "        break  # Exit loop if successful\n",
        "    except Exception as e:\n",
        "        if \"429\" in str(e):  # Check for rate limit error\n",
        "            print(f\"Rate limit hit. Retrying in {delay} seconds... (Attempt {i+1}/{retries})\")\n",
        "            time.sleep(delay)\n",
        "        else:\n",
        "            raise e  # Re-raise other exceptions\n",
        "\n",
        "if local_dir is None:\n",
        "    print(\"Failed to download dataset after multiple retries.\")\n",
        "else:\n",
        "    print(\"Dataset downloaded successfully!\")"
      ],
      "metadata": {
        "id": "C839v3Bu9Uvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start training\n"
      ],
      "metadata": {
        "id": "Yf6BsC7E9ahG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# these info is needed for training\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "metadata": {
        "id": "VrRO3xV69dd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define training configuration\n",
        "# for your own use cases, you might want to change the data paths, model path, run_dir, and other hyperparameters\n",
        "import yaml\n",
        "\n",
        "config = \"\"\"\n",
        "# data\n",
        "data:\n",
        "  train_data: '/content/data/daily-talk-contiguous/dailytalk.jsonl' # Fill\n",
        "  eval_data: '' # Optionally Fill\n",
        "  shuffle: true\n",
        "\n",
        "# model\n",
        "moshi_paths:\n",
        "  hf_repo_id: \"kyutai/moshiko-pytorch-bf16\"\n",
        "\n",
        "\n",
        "full_finetuning: false # Activate lora.enable if partial finetuning\n",
        "lora:\n",
        "  enable: true\n",
        "  rank: 128\n",
        "  scaling: 2.\n",
        "  ft_embed: false\n",
        "\n",
        "# training hyperparameters\n",
        "first_codebook_weight_multiplier: 100.\n",
        "text_padding_weight: .5\n",
        "\n",
        "\n",
        "# tokens per training steps = batch_size x num_GPUs x duration_sec\n",
        "# we recommend a sequence duration of 300 seconds\n",
        "# If you run into memory error, you can try reduce the sequence length\n",
        "duration_sec: 100\n",
        "batch_size: 1\n",
        "max_steps: 300\n",
        "\n",
        "gradient_checkpointing: true # Activate checkpointing of layers\n",
        "\n",
        "# optim\n",
        "optim:\n",
        "  lr: 2.e-6\n",
        "  weight_decay: 0.1\n",
        "  pct_start: 0.05\n",
        "\n",
        "# other\n",
        "seed: 0\n",
        "log_freq: 10\n",
        "eval_freq: 1\n",
        "do_eval: False\n",
        "ckpt_freq: 10\n",
        "\n",
        "save_adapters: True\n",
        "\n",
        "run_dir: \"/content/test\"  # Fill\n",
        "\"\"\"\n",
        "\n",
        "# save the same file locally into the example.yaml file\n",
        "with open(\"/content/example.yaml\", \"w\") as file:\n",
        "    yaml.dump(yaml.safe_load(config), file)"
      ],
      "metadata": {
        "id": "eYOud1039hBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure the run_dir has not been created before\n",
        "# only run this when you ran torchrun previously and created the /content/test_ultra file\n",
        "# ! rm -r /content/test"
      ],
      "metadata": {
        "id": "PN3-oXqa9koV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start training\n",
        "\n",
        "!cd /content/moshi-finetune && torchrun --nproc-per-node 1 -m train /content/example.yaml"
      ],
      "metadata": {
        "id": "Tx_4xEZ29msc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "Once the model has been trained, inference can be run on the colab GPU too, and gradio can be used to tunnel the audio data from a local client to the notebook.\n",
        "\n",
        "More details on how to set this up can be found in the [moshi readme](https://github.com/kyutai-labs/moshi?tab=readme-ov-file#python-pytorch).\n"
      ],
      "metadata": {
        "id": "7cIhKL8k9p9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "jG14wybM9uJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m moshi.server --gradio-tunnel --lora-weight=/content/test/checkpoints/checkpoint_000300/consolidated/lora.safetensors --config-path=/content/test/checkpoints/checkpoint_000300/consolidated/config.json"
      ],
      "metadata": {
        "id": "1EbDO5_h9ye9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}